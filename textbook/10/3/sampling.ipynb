{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling\n",
    "\n",
    "In both experimental and observational studies, the goal is to come to a conclusion about a certain *population*. That population may consist of cancer patients, residents of Hyde Park, or students in this data science course. A survey of every *unit* – or individual member – of a population is known as a *census*. Often, it is not possible to collect data on every subject in a population. For example, I may be able to survey all students in this course, but it would be difficult to survey every Hyde Park resident. This is due to logistical issues, the amount of time it would take, and the expense. For these reasons, researchers often study a *sample* of the population and use that sample to gain information about the entire population through statistical inference. Numerical characteristics of the sample are known as a *statistics*. Statistics are used to estimate or infer values of *parameters*, which are numerical characteristics of the entire population.\n",
    "\n",
    "## Sampling Designs\n",
    "\n",
    "In order to be able to generalize from the sample to the population as a whole, the sample must be *representative* of the population. Otherwise, inference on that sample may produce misleading conclusions. For example, if a researcher is interested in understanding how those living on the southside of Chicago view the University of Chicago, and the researcher collects a sample of 50 first years attending the University of Chicago, the feelings of this sample of first years is most likely not representative of the feelings of everyone living on the southside. Similarly, if a cancer researcher wants to know how well a drug works on cancer patients, but uses a sample consisting only of men under 30, any conclusions she might draw from the experiment cannot be generalized to the entire population but rather only to the population of men under 30.\n",
    "\n",
    "There are several *sampling designs*, or processes by which a sample is collected, that are meant to help collect representative samples. The first is a *simple random sample (SRS)*. In a simple random sample of size `n`, every group of `n` units in the population has an equal chance of being selected as the sample. This eliminates sampling bias by ensuring that portions of the population are not over- or under-sampled. \n",
    "\n",
    "For example, suppose I have five colored marbles in a hat and I draw one marble from the hat without looking. All marbles have the same probability of being selected, one in five. Therefore, my marble choosing example is an SRS. We can conduct an SRS easily in python using a function from the `numpy` library called `random.choice`. The following code uses `np.random.choice` to randomly select a color from the array `marbles` [^*]. By default, it will conduct an SRS, meaning that all elements in `marbles` have an equal chance of being chosen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'brown'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1890)\n",
    "\n",
    "marbles = ['red','blue','yellow','green','brown']\n",
    "np.random.choice(marbles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `np.random.seed()` takes in an integer and uses it to set the state of the random number generator. For now, you don't need to understand how this works, only that it makes the results of our random.choice the same for anyone using the same integer as their seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'brown'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1890)\n",
    "marbles = ['red','blue','yellow','green','brown']\n",
    "np.random.choice(marbles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeating with the same random seed produces the same result: 'brown'. Let's try a new seed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yellow'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(123)\n",
    "marbles = ['red','blue','yellow','green','brown']\n",
    "np.random.choice(marbles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By changing our seed, we got a different result. Throughout this book, we will set random seeds so that, by setting the same seed on your computer, you can replicate the examples done here. \n",
    "\n",
    "Now, suppose I take the yellow, green, and brown marbles out of my hat. Now these marbles have no chance of being chosen and the red and blue marbles each have a 1 in 2 chance of being chosen. We can depict this in code by removing the yellow green and brown elements from the `marbles array` and taking a SRS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'red'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marbles = ['red','blue']\n",
    "np.random.choice(marbles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, we can give different elements different chances of being chosen by using the argument `p` which takes in an array of the same size as marbles. Each element in the `p` array corresponds to an element of marbles. The last 3 elements are 0 since those marbles have no chance of being chosen. The first two are 0.5 or $\\frac{1}{2}$ since they have a 1 in 2 chance of being chosen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blue'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marbles = ['red','blue','yellow','green','brown']\n",
    "np.random.choice(marbles, p=[0.5,0.5,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use `np.random.choice` to take a sample with more than 1 element (sample size > 1) by using the `size` argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['blue', 'green', 'yellow', 'green'], dtype='<U6')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marbles = ['red','blue','yellow','green','brown']\n",
    "np.random.choice(marbles, size= 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that some colors were chosen more than once. The `np.random.choice` function assumes that samples are being takes *with replacement* which means that every time I choose a marble, I put it back in the hat before choosing the next marble. Many times, we want to sample *without replacement*, like in the context of sampling particpants for a survey experiment. The same person cannot participate in your experiment twice. To sample without replacement, set the `replace` argument to `False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['green', 'red', 'brown', 'yellow'], dtype='<U6')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marbles = ['red','blue','yellow','green','brown']\n",
    "np.random.choice(marbles, size= 4, replace=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SRS are very useful in practice as they allow a researcher to mathematically or computationally quantify variation due to sampling (*i.e.* the precision of a statistic). The downside of SRS is that it requires a *sampling frame*, or list of names or IDs of all units in a population. In our marble example, the sampling frame was our `marbles` array and had a size of 5. Aquiring such a sampling frame is impractical for large populations. Now that we have experimented with simple random sampling, we will introduce a few more sampling designs that make use of simple random samples.\n",
    "\n",
    "*Stratified random sampling* divides the population into sub-populations of similar units (called strata) and chooses a separate SRS for each stratum. This allows a researcher to gain more exact information than SRS of the same size, by ensuring that each stratum is equally represented in the sample. Many universities employ stratified random sampling when conducting surveys gauging student or faculty opinions. Those conducting the survey split the population of university students into strata by year (*e.g.* first years, second years, third years, and fourth years); then, they take a simple random sample of students from each stratum. This sampling design works well when cases within a stratum are similar but there are large differences between strata. However, it has the same downside as a SRS as it too needs sampling frames for each stratum.\n",
    "\n",
    "*Cluster sampling* is commonly confused with stratified random sampling as both split the population into sub-populations. However, cluster sampling splits the population into groups called clusters and takes a random sample *of* those clusters rather than taking a random sample *within* groups as in stratified random sampling. Cluster sampling works well when there is small variation between clusters but large variation within clusters and is commonly used for geographical and market research. For example, the head of a major department store may be interested in how well a particular product is selling. Rather than analyzing all sales for all stores across the whole country, the market research team would cluster sales by store and take a random sample of stores.\n",
    "\n",
    "The image below depicts each type of sampling (in maroon) from a population of 100 (in grey). Panel *a* shows the full population before sampling. Panel *b* shows a simple random sample of 10 units. Panel *c* shows a stratified random sample of 10 units with 5 strata. Panel *d* shows a cluster sample of 10 units with 20 clusters.\n",
    "\n",
    "```{figure} ./sampling-schemes.png\n",
    "---\n",
    "align: center\n",
    "---\n",
    "Sampling Designs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next type of sampling we will discuss, *multistage sampling*, conducts sampling in stages and is often used for large nationwide samples of households or individuals. The major advantage of multistage sampling is that it does not require a complete sampling frame. For example, consider a polling company interested in obtaining a generalizable sample of American households. First, they might stratify households by state to ensure sampling from each state. Within states, they might cluster households by county and take a simple random sample of those counties. Lastly, they take a simple random sample of `n` households from each of the sampled counties. This sampling strategy is depicted below. Multistage sampling mixes stratified and cluster sampling in stages and, as a result, the researcher never requires a list of all households in the US, but rather a sampling frame of US counties and then a sampling frame of households within a much smaller subset of US counties.\n",
    "\n",
    "```{figure} ./multistage-sampling.png\n",
    "---\n",
    "align: center\n",
    "---\n",
    "Example of Multistage Sampling\n",
    "```\n",
    "There are two sampling designs that suffer from a lack of generalizability yet sometimes cannot be avoided. The first is known as a *convenience sample*. A convenience sample is, as its name suggests, a sample that is collected out of ease of access for the researchers. Looking through research in psychology in particular, many researchers collect a convenience sample of students from introductory psychology courses. Though this is an easy way of gathering a sample, it is not the most generalizable, as introductory psychology students are likely not representative of the broader population the researchers seek to understand. A second example of a sampling design that is not generalizable is the *voluntary response sample*, where participants volunteer to be part of the study. Restaurant reviews provide a nice example of a voluntary response sample. Those with strong opinions of the restaurant (either positive or negative) are more likely to write reviews. Voluntary response samples oversample those who feel strongly about the topic being studied and undersample those who do not care as much. These samples are always *biased*, or not representative of the broader population."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Biases\n",
    "\n",
    "Recall the introduction to this chapter where we stated that bigger data is not always better. This is often due to the sampling method used to gather that \"Big Data\". We have already discussed the need for representative samples to ensure generalization of the sample to the population. The bias introduced by oversampling some portions of the population over others is known as *selection bias*. However, this is not the only bias that can be introduced during the data collection process. Imagine sampling participants and emailing each participant a survey to complete. Some participants might not complete that survey. *Non-response bias* occurs when the people who decline to respond are different in some meaningful way than those who do respond. Perhaps you wish to study parenting and all single parents were too busy to complete the survey. Your study would be missing an important perspective.\n",
    "\n",
    "Turning attention from those who did not respond to those who did, their responses can suffer from *response bias*. Response bias can appear in multiple formats. Sometimes, participants have an incentive to respond in ways that might not be truthful, especially if questions are sensitive or embarrassing. For example, in a survey of campus sexual health, students might be embarrassed to report STIs, and therefore trends in these data may be misleading. This can be influenced by the wording or tone of the questions as well as if participants have been ensured their data will be kept private. Some response bias can be due more to boredom than truthfulness. For example, especially in long surveys, participants may care more about completing the task than completing the task well. Some participants may choose to select random answers, select the same answer for every question, or answer questions in a pattern. It is important for a researcher to consider the wording, tone and length of a survey carefully, and to check all surveys for possible response bias before analyzing data.\n",
    "\n",
    "Suppose I want to know how many college students have cheated on an exam at some point in their lives. Students are less likely to respond truthfully about cheating which could create response bias in my sample. One strategy for combatting this type of response bias is to use a tecnique known as *random response*. Instead of asking all students to respond truthfully, I ask them to flip 2 coins without letting me see the results. If the first coin lands on heads, they should give a truthful answer. If it lands on tails, they answer \"yes\" if the second coin lands on heads and \"no\" if the second coin lands on tails. This inserts randomness into response ensuring that the researcher does not know who answered truthfully and therefore does not know who has cheated in the past. This encourages students to give truthful answers when prompted and allows the researcher to calculate an estimate of the true proportion of students who have cheated. Let's explore this in a simulation. \n",
    "\n",
    "Let the true proportion of students who have cheated be 40%. We can simulate the truthful answers and coin flips of 100 students using `np.random.choice` as follows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1890)\n",
    "\n",
    "truth = np.random.choice([\"Yes\", \"No\"], 100, p=[0.4, 0.6])\n",
    "flip1 = np.random.choice([\"Heads\", \"Tails\"], 100)\n",
    "flip2 = np.random.choice([\"Heads\", \"Tails\"], 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reported answers given by students in our random response survey would be the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reported = truth.copy()\n",
    "reported[(flip1 == \"Tails\") & (flip2 == \"Heads\")] = \"Yes\"\n",
    "reported[(flip1 == \"Tails\") & (flip2 == \"Tails\")] = \"No\"\n",
    "\n",
    "sum(reported == \"Yes\") / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare this to the true proportion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(truth == \"Yes\") / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the coinflips about half of the participants responded truthfully. We also know that about a quarter of the participants falsely responded \"yes\" and a quarter falsely responded \"no\". Therefore, if we call the probability of truthfully responding \"yes\" $p$, the probability of seeing a response of \"yes\" is $\\frac{1}{2}p + \\frac{1}{4}$. Solving for $p$ the probability of a truthful yes is $2P(yes)-\\frac{1}{2}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * (sum(reported == \"Yes\") / 100) - 1 / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which is a good estimate for our true probability of 40% and the truthful proportion of 0.41."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[^*]: You can also pass an integer to `np.random.choice` instead of an array. This will result in a SRS from the set of integers 0 through but not including the integer you specified. For example, `np.random.choice(5)` would result in a SRS from {0,1,2,3,4}."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
