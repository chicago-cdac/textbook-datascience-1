{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common example of a causal association is a *linear* association or a line. For example, consider the equation for a line $y=2x$. This is an example where changes in $x$ are direct *causes* of changes in $y$. We can see this association by plotting $x$ vs $y$ in a scatterplot as we saw in Chapter (add vizualization chapter number).\n",
    "\n",
    "The following code can be used to make such a scatterplot. First, we import our usual modules and set a random seed as you saw in Chapter 9. Also in Chapter 9, you were introduced to the `random.choice` function from the `numpy` module. That function chooses a value at random from list of potential choices. For our simulation below, we use a similar function `random.normal`. This function chooses values at random from a normal distribution, which we will discuss in more detail in later chapters. We use this function to choose 100 random values to make up our `x` array. Then we define `y` to be $2x$ plus random noise (simulating error and natural variation that exists in the real world) added using our `random.normal` function and make a scatterplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "np.random.seed(1890)\n",
    "\n",
    "x = np.random.normal(size=100)\n",
    "y = 2 * x + np.random.normal(size=100)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.title(\"Scatterplot showing true association between x and y such that y = 2x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This scatterplot depicts a true association between x and y that is present due to the way we defined y to depend on x.\n",
    "\n",
    "Let's use scatterplots as we did earlier to better understand confounding. We create our confounding variable `z` as an array of 100 random values. Next, we define both `x` and `y` to depend explicitly on `z`. When we make the scatterplot, we see an association appear between `x` and `y`. However, when we look at the equations for `x` and `y`, there is no true association (the equation for `x` does not depend on `y` and vice versa). The association in the scatterplot is not causal, it is due to the confounding variable `z`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.random.normal(size=100)\n",
    "x = 2 * z + np.random.normal(size=100)\n",
    "y = z + 4 + np.random.normal(size=100)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.title(\n",
    "    \"Scatterplot showing false association between x and y caused by confounder z\"\n",
    ")\n",
    "plt.ylabel(\"y\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use a scatterplot to understand colliding as well. We create `x` as an array of 100 random values between 0 and 1, this time from a uniform distribution. Imagine these to be probabilities of getting Disease X. We consider those who have probability greater than 50% to have developed the disease. Define `y` to be related to `x` such that those who have Disease X ($x > 0.5$) have twice as high of a score on Measure Y. Next, we define our collider `z` to depend on both `x` and `y`. When we make a scatterplot of `x` and `y`, we see the true association appear between `x` and `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(312)\n",
    "\n",
    "x = np.random.uniform(0, 1, size=100)\n",
    "y = (np.round(x + 1)) * np.random.uniform(0, 1, size=100)\n",
    "z = x + y\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.title(\"Scatterplot showing true association between x and y\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.xlabel(\"x\")\n",
    "c = np.polyfit(x, y, 1)\n",
    "p = np.poly1d(c)\n",
    "plt.plot(x, p(x), \"-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, when we condition on values of our collider by plotting only values of `x` and y for which `z` is greater than 2 (those who have high probability of disease), we see the association between `x` and `y` change directions and appear to be negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dat = pd.DataFrame({\"X\": x, \"Y\": y, \"Z\": z})\n",
    "\n",
    "smallz = dat[dat[\"Z\"] > 2]\n",
    "\n",
    "plt.scatter(smallz.X, smallz.Y)\n",
    "plt.title(\n",
    "    \"Scatterplot showing false association between x and y caused by conditioning on collider z\"\n",
    ")\n",
    "plt.ylabel(\"y\")\n",
    "plt.xlabel(\"x\")\n",
    "c = np.polyfit(smallz.X, smallz.Y, 1)\n",
    "p = np.poly1d(c)\n",
    "plt.plot(smallz.X, p(smallz.X), \"-\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Let's simulate data that suffers from non-response bias. First, we create a ground truth dataset. Imagine we are studying student satisfaction at UChicago and we send surveys to 400 students using stratified random sampling by year in school. Students are asked to rank their satisfaction on a scale of 1 to 5 with 5 being more satisfied and 1 being less satisfied. We also ask students to report their average letter grade. We assume that students with lower grades are more likely to be less satisfied and those with high grades are more likely to be more satisfied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "np.random.seed(92)\n",
    "\n",
    "grades = [\"A\", \"B\", \"C\", \"D\", \"F\"]\n",
    "satisfaction = [1, 2, 3, 4, 5]\n",
    "\n",
    "\n",
    "def get_satisfaction(grade):\n",
    "    if grade == \"A\" or grade == \"B\":\n",
    "        return np.random.choice(satisfaction, 1, p=[0.05, 0.05, 0.2, 0.3, 0.4])\n",
    "    \n",
    "    if grade == \"D\" or grade == \"F\":\n",
    "        return np.random.choice(satisfaction, 1, p=[0.25, 0.35, 0.25, 0.1, 0.05])\n",
    "    \n",
    "    return np.random.choice(satisfaction, 1, p=[0.05, 0.1, 0.25, 0.35, 0.25])\n",
    "\n",
    "\n",
    "get_satisfaction_vec = np.vectorize(get_satisfaction)\n",
    "\n",
    "student_grades = np.random.choice(grades, 400, [0.35, 0.3, 0.25, 0.05, 0.05])\n",
    "\n",
    "student_satisfaction = get_satisfaction_vec(student_grades)\n",
    "\n",
    "student_survey = pd.DataFrame(\n",
    "    {\n",
    "        \"student_grades\": student_grades,\n",
    "        \"student_satisfaction\": student_satisfaction,\n",
    "    }\n",
    ")\n",
    "\n",
    "plt.hist(student_survey.student_satisfaction, bins=[0.5, 1.5, 2.5, 3.5, 4.5, 5.5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, there are more students who are satisfied with UChicago than those who are unsatisfied. However, it is unlikely that all student who are sent the survey will complete it. Assume those with stronger opinions on UChicago are more likely to respond to the survey. Students are busy with schoolwork so those with less strong opinions respond with 50% likelihood."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(sat):\n",
    "    if sat == 1:\n",
    "        return np.random.choice([True, False], 1, p=[0.95, 0.05])\n",
    "    \n",
    "    if sat == 5:\n",
    "        return np.random.choice([True, False], 1, p=[0.8, 0.2])\n",
    "\n",
    "    return np.random.choice([True, False], 1, p=[0.5, 0.5])\n",
    "\n",
    "\n",
    "get_response_vec = np.vectorize(get_response)\n",
    "\n",
    "student_survey[\"response\"] = get_response_vec(student_survey.student_satisfaction)\n",
    "\n",
    "student_survey_biased = student_survey[student_survey[\"response\"] == True]\n",
    "\n",
    "\n",
    "plt.hist(\n",
    "    student_survey_biased.student_satisfaction,\n",
    "    bins=[0.5, 1.5, 2.5, 3.5, 4.5, 5.5],\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The non-response bias changes the distribution of satisfaction scores, making it look like more students are responding with 1's and 5's than there are in truth.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
